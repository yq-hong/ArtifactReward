#!/bin/bash

cd t2i-r1/src
# The latest vllm==0.7.2 is required for this script: pip3 install vllm==0.7.2 
RUN_NAME="run_grpo"

export DEBUG_MODE="true"
export LOG_PATH="src/janus/outputs/debug.txt"
# export NCCL_DEBUG=INFO
mkdir -p $(dirname "$LOG_PATH")

QWEN_PATH="Janus-Pro-1B/"
HF_DATASET="geneval_and_t2i_data_final.json"
OUTPUT_DIR="checkpoint/janus/${RUN_NAME}"
mkdir -p "$OUTPUT_DIR"

# NOTE: you are expected to use X + 1 cards for X training proc and 1 vLLM proc 
# e.g., the visible devices should be 0,1,2,3,4 for 5 cards, and  --nproc_per_node="4"
PYTHONPATH="$(dirname $0)/..":$PYTHONPATH \
CUDA_VISIBLE_DEVICES="1,2,3,4" \
torchrun --nproc_per_node="4" \
--nnodes="1" \
--node_rank="0" \
--master_addr="127.0.0.1" \
--master_port="12345" \
open_r1/grpo.py --use_vllm False \
--deepspeed "src/t2i-r1/configs/zero3.json" \
--output_dir $OUTPUT_DIR \
--model_name_or_path $QWEN_PATH \
--dataset_name $HF_DATASET \
--max_prompt_length 512 \
--max_completion_length 1024 \
--temperature 1.0 \
--num_generations 8 \
--per_device_train_batch_size 1 \
--gradient_accumulation_steps 2 \
--logging_steps 1 \
--bf16  \
--torch_dtype bfloat16 \
--report_to wandb \
--gradient_checkpointing false \
--attn_implementation flash_attention_2 \
--max_steps 3000 \
--run_name $RUN_NAME \
--save_steps 100 \
--new_generations_image 1 \
--image_token_num_per_image 576 \
--cfg_weight 5 \
--reasoning_prompt_path data/prompt/reasoning_prompt.txt \
--reward_funcs orm artifacts \
--beta 0.01 \
--tf32 true \
--learning_rate 1e-6 \
--hps_ckpt_path reward_weight/HPS_v2.1_compressed.pt \
--git_ckpt_path reward_weight/git-large-vqav2 \
--gdino_ckpt_path reward_weight/groundingdino_swint_ogc.pth \
--gdino_config_path src/t2i-r1/src/utils/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py \
--orm_ckpt_path reward_weight/ORM-T2I-R1 \
